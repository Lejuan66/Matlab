Q.1 Pixel (1,1) is located on top left of the image and it has grayvalue of 89. We get the same value with I(1,1).

Q.2 

Q.3 imagesc((I/64)*64) performs an integer division, losing information due to rounding, so when multiplying back we don't get the original values. imagesc((Is/64)*64) operates a real division, so when we multiply we get (almost) the original value (except for representation errors).

Q.4 I_brighter = I + 150;

Q.5 I_lower_contrast = I * 0.2;

Q.6 We have two different gamma transformations of the image, one with gamma > 1, so the resulting image is darker, and one with gamma < 1, so the resulting image is lighter.

Q.7 Histogram equalization works linearising the cumulative distribution, using the cumulative histogram curve as a transformation, flattening the histogram and redistributing the intensity values in a more even fashion. This allows to make details more visible in regions of the image where, in the original image, details where described with close intensity values. 
For the higher brightness image, the histogram shows how we cutted out the values lower than the constant we added (150). For the lower contrast image, the histogram shows how we concentrated all the values in an interval of dark intensity (multiplying by 0.2).

Q.8 The interpolation determines how the intensity of the pixel in the resized image is computed from the original image. Nearest takes the color of the nearest pixel, while bilinear performs bilinear interpolation with the four nearest pixels (row and column neighbours). The antialiasing cuts the higher frequencies, which can generate artifacted patterns in the resulting image if not removed, giving a smoother result.

Q.9

Q.10 (uint32(brain1) + uint32(brain2)) / 2

Q.11 uint32(brain3) - ((uint32(brain1) + uint32(brain2)) / 2)

Q.12 We get overflow and we lose information. We can use a different datatype to handle the problem.

Q.13 Interpolation determines how pixels of the new image are sampled from the values obtained by pure geometrical transformation. Because we are rotating a grid of pixels, the grid of the new image does not map directly into the grid of the original image, so a sampling is needed to determine values for the pixels of the new image.

Q.14 A rotation by multiples of 90 degrees is just a matrix transposition, so it is easier because it does not need any actual computation (only value copy).
